{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "368e115c-8551-4e86-a524-9609193c30bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.42.3-py3-none-any.whl.metadata (43 kB)\n",
      "     ---------------------------------------- 0.0/43.6 kB ? eta -:--:--\n",
      "     -------------------------- ----------- 30.7/43.6 kB 660.6 kB/s eta 0:00:01\n",
      "     -------------------------------------- 43.6/43.6 kB 725.8 kB/s eta 0:00:00\n",
      "Requirement already satisfied: filelock in c:\\users\\darsh\\miniconda3\\envs\\tf\\lib\\site-packages (from transformers) (3.14.0)\n",
      "Collecting huggingface-hub<1.0,>=0.23.2 (from transformers)\n",
      "  Downloading huggingface_hub-0.23.4-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17 in c:\\users\\darsh\\miniconda3\\envs\\tf\\lib\\site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\darsh\\miniconda3\\envs\\tf\\lib\\site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\darsh\\miniconda3\\envs\\tf\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.5.15-cp39-cp39-win_amd64.whl.metadata (41 kB)\n",
      "     ---------------------------------------- 0.0/42.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 42.0/42.0 kB 2.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests in c:\\users\\darsh\\miniconda3\\envs\\tf\\lib\\site-packages (from transformers) (2.32.2)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.3-cp39-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers)\n",
      "  Downloading tokenizers-0.19.1-cp39-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\darsh\\miniconda3\\envs\\tf\\lib\\site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\darsh\\miniconda3\\envs\\tf\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\darsh\\miniconda3\\envs\\tf\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\darsh\\miniconda3\\envs\\tf\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\darsh\\miniconda3\\envs\\tf\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\darsh\\miniconda3\\envs\\tf\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\darsh\\miniconda3\\envs\\tf\\lib\\site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\darsh\\miniconda3\\envs\\tf\\lib\\site-packages (from requests->transformers) (2024.2.2)\n",
      "Downloading transformers-4.42.3-py3-none-any.whl (9.3 MB)\n",
      "   ---------------------------------------- 0.0/9.3 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.6/9.3 MB 12.6 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 2.2/9.3 MB 23.4 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 3.9/9.3 MB 27.5 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 5.2/9.3 MB 27.8 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 6.0/9.3 MB 25.7 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 7.6/9.3 MB 26.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.3/9.3 MB 28.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.3/9.3 MB 27.1 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.23.4-py3-none-any.whl (402 kB)\n",
      "   ---------------------------------------- 0.0/402.6 kB ? eta -:--:--\n",
      "   ------------------ --------------------- 184.3/402.6 kB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 402.6/402.6 kB 4.2 MB/s eta 0:00:00\n",
      "Downloading regex-2024.5.15-cp39-cp39-win_amd64.whl (269 kB)\n",
      "   ---------------------------------------- 0.0/269.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 269.0/269.0 kB ? eta 0:00:00\n",
      "Downloading safetensors-0.4.3-cp39-none-win_amd64.whl (287 kB)\n",
      "   ---------------------------------------- 0.0/287.9 kB ? eta -:--:--\n",
      "   --------------------------------------- 287.9/287.9 kB 17.4 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.19.1-cp39-none-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ------------------------- -------------- 1.4/2.2 MB 44.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 35.1 MB/s eta 0:00:00\n",
      "Installing collected packages: safetensors, regex, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.23.4 regex-2024.5.15 safetensors-0.4.3 tokenizers-0.19.1 transformers-4.42.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32026238-4c6d-4fc1-9999-176b11d830d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\darsh\\miniconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:3101: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\n",
      "Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n",
      "`config.hidden_activation` if you want to override this behaviour.\n",
      "See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fd49abbe1394c81a3cbfd0861ad6388",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\darsh\\miniconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\auto\\processing_auto.py:221: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoProcessor, PaliGemmaForConditionalGeneration\n",
    "\n",
    "model_id = \"google/paligemma-3b-mix-224\"\n",
    "\n",
    "model = PaliGemmaForConditionalGeneration.from_pretrained(model_id)\n",
    "processor = AutoProcessor.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "559a71b2-7247-495e-a4b7-0307939dfe47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "no\n",
      "\n",
      "no\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Prompt and image file path\n",
    "prompt = \"Is there any spill in image?\"\n",
    "image_file = \"C:\\\\Users\\\\darsh\\\\Desktop\"\n",
    "\n",
    "# Open the image from the local file system\n",
    "raw_image = Image.open(image_file)\n",
    "\n",
    "# Assuming 'processor' and 'model' are already defined\n",
    "inputs = processor(prompt, raw_image, return_tensors=\"pt\")\n",
    "output = model.generate(**inputs, max_new_tokens=20)\n",
    "\n",
    "print(processor.decode(output[0], skip_special_tokens=True)[len(prompt):])\n",
    "output= processor.decode(output[0], skip_special_tokens=True)[len(prompt):]\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26285da1-afeb-4f3d-b709-8bb0661437ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nno'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a1bc7b8-1176-4bae-8bc4-ae51b5799019",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'message' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 19\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (output \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124myes\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     12\u001b[0m     message \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mmessages\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m     13\u001b[0m     body\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOil spill detected at warehouse\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     14\u001b[0m     from_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwhatsapp:+14155238886\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# Twilio phone number\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     to\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwhatsapp:+919016939348\u001b[39m\u001b[38;5;124m'\u001b[39m     \u001b[38;5;66;03m# Recipient's phone number\u001b[39;00m\n\u001b[0;32m     16\u001b[0m )\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmessage\u001b[49m\u001b[38;5;241m.\u001b[39msid)  \n",
      "\u001b[1;31mNameError\u001b[0m: name 'message' is not defined"
     ]
    }
   ],
   "source": [
    "    # Import the Twilio client\n",
    "from twilio.rest import Client\n",
    "\n",
    "# Initialize the Twilio client\n",
    "client = Client(account_sid, auth_token)\n",
    "# Send a message\n",
    "if (output == '\\nyes'):\n",
    "        message = client.messages.create(\n",
    "        body='Oil spill detected at warehouse',\n",
    "        from_='whatsapp:+14155238886',  # Twilio phone number\n",
    "        to='whatsapp:'     # Recipient's phone number\n",
    "    )\n",
    "\n",
    "\n",
    "print(message.sid)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e83524-d0fe-42cd-ac2e-af46f933f185",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from tkinter import messagebox\n",
    "from PIL import Image\n",
    "from twilio.rest import Client\n",
    "import torch\n",
    "\n",
    "# Your Twilio credentials\n",
    "\n",
    "# Initialize the Twilio client\n",
    "client = Client(account_sid, auth_token)\n",
    "\n",
    "def process_image(file_path):\n",
    "    prompt = \"Is there any spill in image?\"\n",
    "    raw_image = Image.open(file_path)\n",
    "\n",
    "    inputs = processor(prompt, raw_image, return_tensors=\"pt\")\n",
    "    output = model.generate(**inputs, max_new_tokens=20)\n",
    "\n",
    "    result = processor.decode(output[0], skip_special_tokens=True)[len(prompt):].strip()\n",
    "    return result\n",
    "\n",
    "def upload_image():\n",
    "    file_path = filedialog.askopenfilename()\n",
    "    if file_path:\n",
    "        result = process_image(file_path)\n",
    "        result_label.config(text=f\"Result: {result}\")\n",
    "\n",
    "        # Send a message if spill is detected\n",
    "            message = client.messages.create(\n",
    "                body='Oil spill detected at warehouse',\n",
    "                from_='whatsapp:+14155238886',  # Twilio phone number\n",
    "                to='whatsapp:'  # Recipient's phone number\n",
    "            )\n",
    "            messagebox.showinfo(\"Notification\", f\"Spill detected! Message sent with SID: {message.sid}\")\n",
    "        else:\n",
    "            messagebox.showinfo(\"Result\", \"No spill detected.\")\n",
    "\n",
    "# Create the main window\n",
    "root = tk.Tk()\n",
    "root.title(\"Spill Detection\")\n",
    "\n",
    "# Create a button to upload an image\n",
    "upload_button = tk.Button(root, text=\"Upload Image\", command=upload_image)\n",
    "upload_button.pack(pady=20)\n",
    "\n",
    "# Create a label to show the result\n",
    "result_label = tk.Label(root, text=\"Result: \")\n",
    "result_label.pack(pady=20)\n",
    "\n",
    "# Run the Tkinter event loop\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b6de9301-32d2-4e34-ba78-e29fdbf3516b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-24:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\darsh\\miniconda3\\envs\\tf\\lib\\threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\darsh\\miniconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"C:\\Users\\darsh\\miniconda3\\envs\\tf\\lib\\threading.py\", line 917, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\darsh\\AppData\\Local\\Temp\\ipykernel_33312\\2262697452.py\", line 49, in process_and_notify\n",
      "  File \"C:\\Users\\darsh\\AppData\\Local\\Temp\\ipykernel_33312\\2262697452.py\", line 33, in process_image2\n",
      "  File \"C:\\Users\\darsh\\miniconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\paligemma\\processing_paligemma.py\", line 296, in decode\n",
      "    return self.tokenizer.decode(*args, **kwargs)\n",
      "  File \"C:\\Users\\darsh\\miniconda3\\envs\\tf\\lib\\site-packages\\transformers\\tokenization_utils_base.py\", line 3906, in decode\n",
      "    return self._decode(\n",
      "  File \"C:\\Users\\darsh\\miniconda3\\envs\\tf\\lib\\site-packages\\transformers\\tokenization_utils_fast.py\", line 651, in _decode\n",
      "    text = self._tokenizer.decode(token_ids, skip_special_tokens=skip_special_tokens)\n",
      "TypeError: argument 'ids': 'list' object cannot be interpreted as an integer\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[97], line 75\u001b[0m\n\u001b[0;32m     72\u001b[0m result_label\u001b[38;5;241m.\u001b[39mpack(pady\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# Run the Tkinter event loop\u001b[39;00m\n\u001b[1;32m---> 75\u001b[0m \u001b[43mroot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmainloop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf\\lib\\tkinter\\__init__.py:1429\u001b[0m, in \u001b[0;36mMisc.mainloop\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m   1427\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmainloop\u001b[39m(\u001b[38;5;28mself\u001b[39m, n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m   1428\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the mainloop of Tk.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1429\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmainloop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from tkinter import messagebox\n",
    "from PIL import Image\n",
    "from twilio.rest import Client\n",
    "import threading\n",
    "import torch\n",
    "\n",
    "\n",
    "# Initialize the Twilio client\n",
    "client = Client(account_sid, auth_token)\n",
    "\n",
    "def process_image(file_path):\n",
    "    prompt = \"Is there any spill in image?\"\n",
    "    raw_image = Image.open(file_path)\n",
    "\n",
    "    inputs = processor(prompt, raw_image, return_tensors=\"pt\")\n",
    "    output = model.generate(**inputs, max_new_tokens=20)\n",
    "\n",
    "    result = processor.decode(output[0], skip_special_tokens=True)[len(prompt):].strip()\n",
    "    return result\n",
    "\n",
    "def upload_image():\n",
    "    file_path = filedialog.askopenfilename()\n",
    "    if file_path:\n",
    "        result_label.config(text=\"Processing...\", fg=\"blue\")\n",
    "        threading.Thread(target=process_and_notify, args=(file_path,)).start()\n",
    "\n",
    "def process_and_notify(file_path):\n",
    "    result = process_image(file_path)\n",
    "    root.after(0, update_ui, result)\n",
    "        message = client.messages.create(\n",
    "            body='Oil spill detected at warehouse'+process_image2(file_path),\n",
    "            from_='whatsapp:+14155238886',  # Twilio phone number\n",
    "            to='whatsapp:'  # Recipient's phone number\n",
    "        )\n",
    "        root.after(0, messagebox.showinfo, \"Notification\", f\"Spill detected! Message sent with SID: {message.sid}\")\n",
    "    else:\n",
    "        root.after(0, messagebox.showinfo, \"Result\", \"No spill detected.\")\n",
    "\n",
    "def update_ui(result):\n",
    "    result_label.config(text=f\"Result: {result}\", fg=\"green\" if result.lower() == 'yes' else \"red\")\n",
    "\n",
    "# Create the main window\n",
    "root = tk.Tk()\n",
    "root.title(\"Spill Detection\")\n",
    "root.geometry(\"400x300\")\n",
    "root.configure(bg=\"#f0f0f0\")\n",
    "\n",
    "# Create a button to upload an image\n",
    "upload_button = tk.Button(root, text=\"Upload Image\", command=upload_image, bg=\"#4CAF50\", fg=\"white\", font=(\"Helvetica\", 12, \"bold\"))\n",
    "upload_button.pack(pady=20)\n",
    "\n",
    "# Create a label to show the result\n",
    "result_label = tk.Label(root, text=\"Result: \", bg=\"#f0f0f0\", font=(\"Helvetica\", 14))\n",
    "result_label.pack(pady=20)\n",
    "\n",
    "# Run the Tkinter event loop\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6ac4f37-6593-4086-89f4-3e18d8b889d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from tkinter import messagebox\n",
    "from PIL import Image\n",
    "from twilio.rest import Client\n",
    "import threading\n",
    "import torch\n",
    "\n",
    "# Initialize the Twilio client\n",
    "client = Client(account_sid, auth_token)\n",
    "\n",
    "def process_image(file_path):\n",
    "    prompt = \"Is there any spill in image?\"\n",
    "    raw_image = Image.open(file_path)\n",
    "\n",
    "    inputs = processor(prompt, raw_image, return_tensors=\"pt\")\n",
    "    output = model.generate(**inputs, max_new_tokens=20)\n",
    "\n",
    "    result = processor.decode(output[0], skip_special_tokens=True)[len(prompt):].strip()\n",
    "    return result\n",
    "\n",
    "def upload_image():\n",
    "    file_path = filedialog.askopenfilename()\n",
    "    if file_path:\n",
    "        result_label.config(text=\"Processing...\", fg=\"blue\")\n",
    "        threading.Thread(target=process_and_notify, args=(file_path,)).start()\n",
    "\n",
    "def process_and_notify(file_path):\n",
    "    result = process_image(file_path)\n",
    "    root.after(0, update_ui, result)\n",
    "\n",
    "        message = client.messages.create(\n",
    "            body='''############ Alert ############\n",
    "    Please Check the Ware House facility in Zone-1 area. There is a Oil spill.''',\n",
    "            from_='whatsapp:+14155238886',  # Twilio phone number\n",
    "            to= 'whatsapp:' # Recipient's phone number\n",
    "        )\n",
    "        root.after(0, messagebox.showinfo, \"Notification\", f\"Spill detected! Message sent with SID: {message.sid}\")\n",
    "    else:\n",
    "        root.after(0, messagebox.showinfo, \"Result\", \"No spill detected.\")\n",
    "\n",
    "def update_ui(result):\n",
    "    result_label.config(text=f\"Result: {result}\", fg=\"green\" if result.lower() == 'yes' else \"red\")\n",
    "\n",
    "# Create the main window\n",
    "root = tk.Tk()\n",
    "root.title(\"Spill Detection\")\n",
    "root.geometry(\"400x400\")\n",
    "root.configure(bg=\"#f0f0f0\")\n",
    "\n",
    "# Create a frame to center align all elements\n",
    "frame = tk.Frame(root, bg=\"#f0f0f0\")\n",
    "frame.place(relx=0.5, rely=0.5, anchor=\"center\")\n",
    "\n",
    "# Add a title label\n",
    "title_label = tk.Label(frame, text=\"Spill Detection System\", bg=\"#f0f0f0\", font=(\"Helvetica\", 20, \"bold\"))\n",
    "title_label.pack(pady=10)\n",
    "\n",
    "# Add an instruction label\n",
    "instruction_label = tk.Label(frame, text=\"Upload an image to check for any spills. The system will notify if a spill is detected.\", \n",
    "                             bg=\"#f0f0f0\", font=(\"Helvetica\", 12), wraplength=350)\n",
    "instruction_label.pack(pady=10)\n",
    "\n",
    "# Create a button to upload an image\n",
    "upload_button = tk.Button(frame, text=\"Upload Image\", command=upload_image, bg=\"#4CAF50\", fg=\"white\", font=(\"Helvetica\", 15, \"bold\"))\n",
    "upload_button.pack(pady=20)\n",
    "\n",
    "# Create a label to show the result\n",
    "result_label = tk.Label(frame, text=\"Result: \", bg=\"#f0f0f0\", font=(\"Helvetica\", 17))\n",
    "result_label.pack(pady=20)\n",
    "\n",
    "# Add a footer label\n",
    "footer_label = tk.Label(frame, text=\" Project by Team Nirmaan \", bg=\"#f0f0f0\", font=(\"Helvetica\", 10, \"italic\"))\n",
    "footer_label.pack(pady=10)\n",
    "\n",
    "# Run the Tkinter event loop\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcc5078-b492-4a1a-8fae-9da38155d96c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90fb867-0fe0-4fae-ba8c-368ae4565d1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
